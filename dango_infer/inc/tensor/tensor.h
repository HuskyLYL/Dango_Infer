#ifndef DANGO_INCLUDE_TENSOR_TENSOR_H_
#define DANGO_INCLUDE_TENSOR_TENSOR_H_
#include <driver_types.h>
#include <glog/logging.h>
#include <armadillo>
#include <memory>
#include <vector>
#include "base/base.h"
#include "base/buffer.h"
namespace tensor 
{


  class Tensor 
  {
  public: 

    explicit Tensor() = default;


    explicit Tensor(int32_t dim0, base::deviceId device_id,base::DataType data_type,void* ptr = nullptr);


    explicit Tensor(int32_t dim0, int32_t dim1, base::deviceId device_id,base::DataType data_type,void* ptr = nullptr);


    explicit Tensor(int32_t dim0, int32_t dim1, int32_t dim2,base::deviceId device_id,base::DataType data_type,void* ptr = nullptr);


    explicit Tensor(int32_t dim0, int32_t dim1, int32_t dim2, int32_t dim3,base::deviceId device_id,base::DataType data_type,void* ptr = nullptr);


    explicit Tensor(std::vector<int32_t> dims,base::deviceId device_id,base::DataType data_type,void* ptr = nullptr);





    void to_device(base::deviceId device_id ,cudaStream_t stm = nullptr);

    bool is_empty() const;



    template <typename T>
    T* ptr();

    template <typename T>
    const T* ptr() const;

    void reshape(const std::vector<int32_t>& dims);

    std::shared_ptr<base::Buffer> get_buffer() const;

    size_t size() const;

    size_t byte_size() const;

    int32_t dims_size() const;

    base::DataType data_type() const;

    int32_t get_dim(int32_t idx) const;

    const std::vector<int32_t>& dims() const;

    std::vector<size_t> strides() const;

    bool assign(std::shared_ptr<base::Buffer> buffer);

    void reset(base::DataType data_type, const std::vector<int32_t>& dims);





    base::deviceId getDeviceId() const;

    template <typename T>
    T* ptr(int64_t index);

    template <typename T>
    const T* ptr(int64_t index) const;

    template <typename T>
    T& index(int64_t offset);

    template <typename T>
    const T& index(int64_t offset) const;

    tensor::Tensor clone() const;

  private:
    size_t size_ = 0;
    std::vector<int32_t> dims_;
    std::shared_ptr<base::Buffer> buffer_;
    base::DataType data_type_;
  };

  template <typename T>
  T& Tensor::index(int64_t offset) 
  {
    CHECK_GE(offset, 0);
    CHECK_LT(offset, this->size());
    T& val = *(reinterpret_cast<T*>(buffer_->ptr()) + offset);
    return val;
  }

  template <typename T>
  const T& Tensor::index(int64_t offset) const 
  {
    CHECK_GE(offset, 0);
    CHECK_LT(offset, this->size());
    const T& val = *(reinterpret_cast<T*>(buffer_->ptr()) + offset);
    return val;
  }

  template <typename T>
  const T* Tensor::ptr() const 
  {
    if (!buffer_) 
      return nullptr;
    return const_cast<const T*>(reinterpret_cast<T*>(buffer_->ptr()));
  }

  template <typename T>
  T* Tensor::ptr() 
  {
    if (!buffer_) 
      return nullptr;
    return reinterpret_cast<T*>(buffer_->ptr());
  }

  template <typename T>
  T* Tensor::ptr(int64_t index) 
  {
    CHECK(buffer_ != nullptr && buffer_->ptr() != nullptr)
      << "The data area buffer of this tensor is empty or it points to a null pointer.";
    return const_cast<T*>(reinterpret_cast<const T*>(buffer_->ptr())) + index;
  }

  template <typename T>
  const T* Tensor::ptr(int64_t index) const 
  {
    CHECK(buffer_ != nullptr && buffer_->ptr() != nullptr)
      << "The data area buffer of this tensor is empty or it points to a null pointer.";
    return reinterpret_cast<const T*>(buffer_->ptr()) + index;
  }
}  
#endif  
